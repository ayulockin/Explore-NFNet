{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train NF-ResNet on Cifar-10 using PyTorch Lightning",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYdxCExvgJnHzgRrywIkGq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c39f040486384f0a88ff210aae7de30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_534fd7c31ef74a6bb0a65e0a9a2c4c7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_46ebcc170699436b81b2d70fffc01c2a",
              "IPY_MODEL_4f796d7c1e314c10bb0cab694ea58a6f"
            ]
          }
        },
        "534fd7c31ef74a6bb0a65e0a9a2c4c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46ebcc170699436b81b2d70fffc01c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee994141e4474b169ebf39c7227cd254",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_592dc6f7aef9465a935ae5188e79c67c"
          }
        },
        "4f796d7c1e314c10bb0cab694ea58a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1807c1e6edc449d8813385efb05e33d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 136396800/? [00:09&lt;00:00, 13877658.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df56eb4162a342789f3b53f6ef23e0c5"
          }
        },
        "ee994141e4474b169ebf39c7227cd254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "592dc6f7aef9465a935ae5188e79c67c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1807c1e6edc449d8813385efb05e33d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df56eb4162a342789f3b53f6ef23e0c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/Explore-NFNet/blob/main/Train_NF_ResNet_on_Cifar_10_using_PyTorch_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MirDQLgiwyi2"
      },
      "source": [
        "## ⚙️ Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evscgXTFwszZ"
      },
      "source": [
        "%%capture\n",
        "# Install pytorch lighting\n",
        "!pip install pytorch-lightning --quiet\n",
        "# Install weights and biases\n",
        "!pip install wandb --quiet\n",
        "# Install patool to unrar dataset file\n",
        "!pip install patool"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX7QXaoVz3OC",
        "outputId": "c2d2d5dc-2b46-461f-e92b-a79502179f54"
      },
      "source": [
        "!git clone https://github.com/rwightman/pytorch-image-models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-image-models'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 4632 (delta 21), reused 33 (delta 10), pack-reused 4573\u001b[K\n",
            "Receiving objects: 100% (4632/4632), 15.82 MiB | 27.13 MiB/s, done.\n",
            "Resolving deltas: 100% (3320/3320), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieJ6Kl7ixBFT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "22c5d74e-7bee-4a9b-d6c3-161c67009da2"
      },
      "source": [
        "# regular imports\n",
        "import sys\n",
        "sys.path.append(\"pytorch-image-models\")\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import patoolib\n",
        "\n",
        "# pytorch related imports \n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets.utils import download_url\n",
        "\n",
        "# import for nfnet\n",
        "import timm\n",
        "\n",
        "# lightning related imports\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.metrics.functional import accuracy\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# sklearn related imports\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# import wandb and login\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_11_ucfHiXN"
      },
      "source": [
        "## 🎨 Using DataModules - `Clatech101DataModule`\n",
        "\n",
        "DataModules are a way of decoupling data-related hooks from the `LightningModule` so you can develop dataset agnostic models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUtllNR5NwaK"
      },
      "source": [
        "class Caltech101DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size, data_dir: str = './'):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Augmentation policy\n",
        "        self.augmentation = transforms.Compose([\n",
        "              transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "              transforms.RandomRotation(degrees=15),\n",
        "              transforms.RandomHorizontalFlip(),\n",
        "              transforms.CenterCrop(size=224),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.transform = transforms.Compose([\n",
        "              transforms.Resize(size=256),\n",
        "              transforms.CenterCrop(size=224),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        \n",
        "        self.num_classes = 102\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # source: https://figshare.com/articles/dataset/Caltech101_Image_Dataset/7007090\n",
        "        url = 'https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/12855005/Caltech101ImageDataset.rar'\n",
        "        # download\n",
        "        download_url(url, self.data_dir)\n",
        "        # extract \n",
        "        patoolib.extract_archive(\"Caltech101ImageDataset.rar\", outdir=self.data_dir)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # build dataset\n",
        "        caltect_dataset = ImageFolder('Caltech101')\n",
        "        # split dataset\n",
        "        self.train, self.val, self.test = random_split(caltect_dataset, [6500, 1000, 1645])\n",
        "        self.train.dataset.transform = self.augmentation\n",
        "        self.val.dataset.transform = self.transform\n",
        "        self.test.dataset.transform = self.transform\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test, batch_size=self.batch_size)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkeBFJBkYJr1"
      },
      "source": [
        "## 📲 Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBz4YZvYg-jc"
      },
      "source": [
        "#### 🚏 Earlystopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9gvY3pfYLOm"
      },
      "source": [
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='val_loss',\n",
        "   patience=3,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dhQJeOXhAmC"
      },
      "source": [
        "#### 🛃 Custom Callback - `ImagePredictionLogger`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GdiZ0b2FTfF"
      },
      "source": [
        "class ImagePredictionLogger(Callback):\n",
        "    def __init__(self, val_samples, num_samples=32):\n",
        "        super().__init__()\n",
        "        self.num_samples = num_samples\n",
        "        self.val_imgs, self.val_labels = val_samples\n",
        "        \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
        "        val_labels = self.val_labels.to(device=pl_module.device)\n",
        "       \n",
        "        logits = pl_module(val_imgs)\n",
        "        preds = torch.argmax(logits, -1)\n",
        "        \n",
        "        trainer.logger.experiment.log({\n",
        "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
        "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
        "                                                 preds[:self.num_samples], \n",
        "                                                 val_labels[:self.num_samples])]\n",
        "            })"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpqnhW1xFAGH"
      },
      "source": [
        "#### 💾 Model Checkpoint Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUiYNQbEG01y"
      },
      "source": [
        "MODEL_CKPT_PATH = 'model/'\n",
        "MODEL_CKPT = 'model/model-{epoch:02d}-{val_loss:.2f}'\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    filename=MODEL_CKPT,\n",
        "    save_top_k=3,\n",
        "    mode='min')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AegEWlwjS7Gv"
      },
      "source": [
        "## 🎺 Define The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKBN_rFfP0mL"
      },
      "source": [
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self, input_shape, num_classes, learning_rate=2e-4):\n",
        "        super().__init__()\n",
        "        \n",
        "        # log hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.dim = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        self.classifier = timm.create_model('nf_resnet50', pretrained=False, num_classes=num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      #  x = self._forward_features(x)\n",
        "      #  x = x.view(x.size(0), -1)\n",
        "       x = F.log_softmax(self.classifier(x), dim=1)\n",
        "       \n",
        "       return x\n",
        "\n",
        "    # logic for a single training step\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "        \n",
        "        # training metrics\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    # logic for a single validation step\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        # validation metrics\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    # logic for a single testing step\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "        \n",
        "        # validation metrics\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "        self.log('test_loss', loss, prog_bar=True)\n",
        "        self.log('test_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceYFNcOuh9fP"
      },
      "source": [
        "## ⚡ Train and Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvY-POwDT3Fi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "c39f040486384f0a88ff210aae7de30b",
            "534fd7c31ef74a6bb0a65e0a9a2c4c7b",
            "46ebcc170699436b81b2d70fffc01c2a",
            "4f796d7c1e314c10bb0cab694ea58a6f",
            "ee994141e4474b169ebf39c7227cd254",
            "592dc6f7aef9465a935ae5188e79c67c",
            "1807c1e6edc449d8813385efb05e33d0",
            "df56eb4162a342789f3b53f6ef23e0c5"
          ]
        },
        "outputId": "47f7e25d-e3e4-49ae-d0d6-9c706dccbd95"
      },
      "source": [
        "# Init our data pipeline\n",
        "BATCH_SIZE = 32\n",
        "dm = Caltech101DataModule(batch_size=BATCH_SIZE)\n",
        "# To access the x_dataloader we need to call prepare_data and setup.\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "\n",
        "# Samples required by the custom ImagePredictionLogger callback to log image predictions.\n",
        "val_samples = next(iter(dm.val_dataloader()))\n",
        "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
        "val_imgs.shape, val_labels.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/12855005/Caltech101ImageDataset.rar to ./Caltech101ImageDataset.rar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c39f040486384f0a88ff210aae7de30b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "patool: Extracting Caltech101ImageDataset.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/Caltech101ImageDataset.rar\n",
            "patool:     with cwd='./'\n",
            "patool: ... Caltech101ImageDataset.rar extracted to `./'.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 3, 224, 224]), torch.Size([256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjZi8Ya-fAa9"
      },
      "source": [
        "# Init our model\n",
        "model = LitModel((3,224,224), 102)\n",
        "\n",
        "# Initialize wandb logger\n",
        "wandb_logger = WandbLogger(project='nfnet', job_type='train-nf-resnet')\n",
        "\n",
        "# Initialize a trainer\n",
        "trainer = pl.Trainer(max_epochs=50,\n",
        "                     progress_bar_refresh_rate=20, \n",
        "                     gpus=1, \n",
        "                     logger=wandb_logger,\n",
        "                     callbacks=[early_stop_callback,\n",
        "                                ImagePredictionLogger(val_samples)],\n",
        "                     checkpoint_callback=checkpoint_callback)\n",
        "\n",
        "# Train the model ⚡🚅⚡\n",
        "trainer.fit(model, dm) \n",
        "\n",
        "# Evaluate the model on the held out test set ⚡⚡\n",
        "trainer.test()\n",
        "\n",
        "# Close wandb run\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}